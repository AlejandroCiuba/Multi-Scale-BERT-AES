2024-11-18 04:22:13 : ===================== 2024-11-18T04:22:13.203800 =====================
2024-11-18 04:22:13 : ===================== FINE-TUNING ON PROMPT 7 =====================
2024-11-18 04:22:13 : Settings: Namespace(data='init/asap_5_splits.csv', bert_model_path='../../../ix/ix_models/Multi-Scale-BERT-AES-Models/p8_3', chunk_sizes='90_30_130_10', prompt=[7], batch_size=16, epochs=80, sample=-1, learning_rate=6e-05, result_file='results/finetune/p7.txt', save_model='../../../ix/ix_models/Multi-Scale-BERT-AES-Models/p7/p7.pt', device='cuda', log=PosixPath('logs/finetune-7.log'), comment='Using google-bert/bert-base-uncased. Removed the direct path to their finetuned word and chunk models.')
2024-11-18 04:22:13 : Additional Comments: Using google-bert/bert-base-uncased. Removed the direct path to their finetuned word and chunk models.
2024-11-18 04:22:22 : Train/Eval/Test: 918/337/314
2024-11-18 04:22:22 : Started training loop for p7.pt
2024-11-18 04:22:28 : 1/80 | 1/58: 97.80029
2024-11-18 04:22:29 : 1/80 | 2/58: 78.25021
2024-11-18 04:22:31 : 1/80 | 3/58: 65.48242
2024-11-18 04:22:33 : 1/80 | 4/58: 49.26832
2024-11-18 04:22:34 : 1/80 | 5/58: 45.26430
2024-11-18 04:22:36 : 1/80 | 6/58: 37.46261
2024-11-18 04:22:38 : 1/80 | 7/58: 31.57790
2024-11-18 04:22:39 : 1/80 | 8/58: 28.47932
2024-11-18 04:22:41 : 1/80 | 9/58: 22.18030
2024-11-18 04:22:43 : 1/80 | 10/58: 18.03591
2024-11-18 04:22:44 : 1/80 | 11/58: 13.60002
2024-11-18 04:22:46 : 1/80 | 12/58: 12.68450
2024-11-18 04:22:47 : 1/80 | 13/58: 10.49286
2024-11-18 04:22:49 : 1/80 | 14/58: 12.06192
2024-11-18 04:22:51 : 1/80 | 15/58: 14.03199
2024-11-18 04:22:52 : 1/80 | 16/58: 12.15669
2024-11-18 04:22:54 : 1/80 | 17/58: 12.43059
2024-11-18 04:22:56 : 1/80 | 18/58: 12.44412
2024-11-18 04:22:57 : 1/80 | 19/58: 11.52198
2024-11-18 04:22:59 : 1/80 | 20/58: 10.71401
2024-11-18 04:23:00 : 1/80 | 21/58: 8.02524
2024-11-18 04:23:02 : 1/80 | 22/58: 8.65746
2024-11-18 04:23:04 : 1/80 | 23/58: 9.38439
2024-11-18 04:23:05 : 1/80 | 24/58: 9.87722
2024-11-18 04:23:07 : 1/80 | 25/58: 10.70352
2024-11-18 04:23:09 : 1/80 | 26/58: 8.55677
2024-11-18 04:23:10 : 1/80 | 27/58: 7.22862
2024-11-18 04:23:12 : 1/80 | 28/58: 7.30782
2024-11-18 04:23:13 : 1/80 | 29/58: 7.63047
2024-11-18 04:23:15 : 1/80 | 30/58: 6.45912
2024-11-18 04:23:17 : 1/80 | 31/58: 5.44265
2024-11-18 04:23:18 : 1/80 | 32/58: 5.21199
2024-11-18 04:23:20 : 1/80 | 33/58: 4.48246
2024-11-18 04:23:21 : 1/80 | 34/58: 3.43426
2024-11-18 04:23:23 : 1/80 | 35/58: 5.11438
2024-11-18 04:23:25 : 1/80 | 36/58: 4.38843
2024-11-18 04:23:26 : 1/80 | 37/58: 4.01765
2024-11-18 04:23:28 : 1/80 | 38/58: 3.25790
2024-11-18 04:23:29 : 1/80 | 39/58: 3.01562
2024-11-18 04:23:31 : 1/80 | 40/58: 3.02441
2024-11-18 04:23:33 : 1/80 | 41/58: 2.13599
2024-11-18 04:23:34 : 1/80 | 42/58: 1.56468
2024-11-18 04:23:36 : 1/80 | 43/58: 1.57384
2024-11-18 04:23:38 : 1/80 | 44/58: 1.48950
2024-11-18 04:23:39 : 1/80 | 45/58: 1.15570
2024-11-18 04:23:41 : 1/80 | 46/58: 1.09764
2024-11-18 04:23:42 : 1/80 | 47/58: 0.76830
2024-11-18 04:23:44 : 1/80 | 48/58: 0.45694
2024-11-18 04:23:46 : 1/80 | 49/58: 0.76822
2024-11-18 04:23:47 : 1/80 | 50/58: 0.75474
2024-11-18 04:23:49 : 1/80 | 51/58: 1.10267
2024-11-18 04:23:50 : 1/80 | 52/58: 1.22089
2024-11-18 04:23:52 : 1/80 | 53/58: 3.00920
2024-11-18 04:23:54 : 1/80 | 54/58: 1.50462
2024-11-18 04:23:55 : 1/80 | 55/58: 0.90639
2024-11-18 04:23:57 : 1/80 | 56/58: 1.99286
2024-11-18 04:23:58 : 1/80 | 57/58: 0.65564
2024-11-18 04:24:00 : 1/80 | 58/58: 1.92416
2024-11-19 00:04:21 : ===================== 2024-11-19T00:04:21.673142 =====================
2024-11-19 00:04:21 : ===================== FINE-TUNING ON PROMPT 7 =====================
2024-11-19 00:04:21 : Settings: Namespace(data='init/asap_5_splits.csv', bert_model_path='../../../ix/ix_models/Multi-Scale-BERT-AES-Models/p8_3', chunk_sizes='90_30_130_10', prompt=[7], batch_size=16, epochs=1, sample=-1, learning_rate=6e-05, result_file='results/finetune/p7.txt', save_model='../../../ix/ix_models/Multi-Scale-BERT-AES-Models/p7/p7.pt', device='cuda', log=PosixPath('logs/finetune-7.log'), comment='Using google-bert/bert-base-uncased. Removed the direct path to their finetuned word and chunk models.')
2024-11-19 00:04:21 : Additional Comments: Using google-bert/bert-base-uncased. Removed the direct path to their finetuned word and chunk models.
2024-11-19 00:04:31 : Train/Eval/Test: 918/337/314
2024-11-19 00:04:31 : Started training loop for p7.pt
2024-11-19 00:04:37 : 1/1 | 1/58: 95.72650
2024-11-19 00:04:39 : 1/1 | 2/58: 78.29964
2024-11-19 00:04:40 : 1/1 | 3/58: 65.31831
2024-11-19 00:04:42 : 1/1 | 4/58: 49.79036
2024-11-19 00:04:44 : 1/1 | 5/58: 47.11199
2024-11-19 00:04:45 : 1/1 | 6/58: 41.32237
2024-11-19 00:04:47 : 1/1 | 7/58: 37.76865
2024-11-19 00:04:49 : 1/1 | 8/58: 36.07658
2024-11-19 00:04:50 : 1/1 | 9/58: 27.85927
2024-11-19 00:04:52 : 1/1 | 10/58: 22.65143
2024-11-19 00:04:54 : 1/1 | 11/58: 15.55751
2024-11-19 00:04:55 : 1/1 | 12/58: 14.91651
2024-11-19 00:04:57 : 1/1 | 13/58: 12.20068
2024-11-19 00:04:59 : 1/1 | 14/58: 13.53473
2024-11-19 00:05:00 : 1/1 | 15/58: 16.07760
2024-11-19 00:05:02 : 1/1 | 16/58: 14.27787
2024-11-19 00:05:04 : 1/1 | 17/58: 14.49345
2024-11-19 00:05:05 : 1/1 | 18/58: 13.81868
2024-11-19 00:05:07 : 1/1 | 19/58: 12.13917
2024-11-19 00:05:09 : 1/1 | 20/58: 12.42900
2024-11-19 00:05:10 : 1/1 | 21/58: 9.52830
2024-11-19 00:05:12 : 1/1 | 22/58: 8.38376
2024-11-19 00:05:14 : 1/1 | 23/58: 9.25659
2024-11-19 00:05:15 : 1/1 | 24/58: 12.19465
2024-11-19 00:05:17 : 1/1 | 25/58: 12.82367
2024-11-19 00:05:19 : 1/1 | 26/58: 10.07240
2024-11-19 00:05:20 : 1/1 | 27/58: 10.33087
2024-11-19 00:05:22 : 1/1 | 28/58: 9.26792
2024-11-19 00:05:24 : 1/1 | 29/58: 10.44844
2024-11-19 00:05:25 : 1/1 | 30/58: 9.91789
2024-11-19 00:05:27 : 1/1 | 31/58: 9.07650
2024-11-19 00:05:29 : 1/1 | 32/58: 7.93863
2024-11-19 00:05:30 : 1/1 | 33/58: 7.05697
2024-11-19 00:05:32 : 1/1 | 34/58: 7.51278
2024-11-19 00:05:34 : 1/1 | 35/58: 7.57376
2024-11-19 00:05:35 : 1/1 | 36/58: 9.93628
2024-11-19 00:05:37 : 1/1 | 37/58: 8.58201
2024-11-19 00:05:39 : 1/1 | 38/58: 8.22729
2024-11-19 00:05:40 : 1/1 | 39/58: 5.72114
2024-11-19 00:05:42 : 1/1 | 40/58: 5.01009
2024-11-19 00:05:44 : 1/1 | 41/58: 4.17533
2024-11-19 00:05:45 : 1/1 | 42/58: 2.57390
2024-11-19 00:05:47 : 1/1 | 43/58: 2.74818
2024-11-19 00:05:49 : 1/1 | 44/58: 2.33122
2024-11-19 00:05:50 : 1/1 | 45/58: 2.19509
2024-11-19 00:05:52 : 1/1 | 46/58: 2.35847
2024-11-19 00:05:54 : 1/1 | 47/58: 1.39761
2024-11-19 00:05:55 : 1/1 | 48/58: 1.25984
2024-11-19 00:05:57 : 1/1 | 49/58: 1.49449
2024-11-19 00:05:59 : 1/1 | 50/58: 1.24725
2024-11-19 00:06:00 : 1/1 | 51/58: 1.27323
2024-11-19 00:06:02 : 1/1 | 52/58: 2.29621
2024-11-19 00:06:04 : 1/1 | 53/58: 1.89296
2024-11-19 00:06:05 : 1/1 | 54/58: 1.74510
2024-11-19 00:06:07 : 1/1 | 55/58: 0.88325
2024-11-19 00:06:08 : 1/1 | 56/58: 0.59734
2024-11-19 00:06:10 : 1/1 | 57/58: 0.72812
2024-11-19 00:06:12 : 1/1 | 58/58: 1.25558
2024-11-19 02:14:18 : ===================== 2024-11-19T02:14:18.028740 =====================
2024-11-19 02:14:18 : ===================== FINE-TUNING ON PROMPT 7 =====================
2024-11-19 02:14:18 : Settings: Namespace(data='init/asap_5_splits.csv', bert_model_path='../../../ix/ix_models/Multi-Scale-BERT-AES-Models/p8_3', chunk_sizes='90_30_130_10', prompt=[7], batch_size=16, epochs=1, sample=-1, learning_rate=6e-05, result_file='results/finetune/p7.txt', save_model='../../../ix/ix_models/Multi-Scale-BERT-AES-Models/p7/p7.pt', device='cuda', log=PosixPath('logs/finetune-7.log'), comment='Using google-bert/bert-base-uncased. Removed the direct path to their finetuned word and chunk models.')
2024-11-19 02:14:18 : Additional Comments: Using google-bert/bert-base-uncased. Removed the direct path to their finetuned word and chunk models.
2024-11-19 02:14:27 : Train/Eval/Test: 918/337/314
2024-11-19 02:14:27 : Started training loop for p7.pt
2024-11-19 02:14:32 : 1/1 | 1/58: 103.51819
2024-11-19 02:14:34 : 1/1 | 2/58: 83.91833
2024-11-19 02:14:36 : 1/1 | 3/58: 74.83127
2024-11-19 02:14:37 : 1/1 | 4/58: 62.50517
2024-11-19 02:14:39 : 1/1 | 5/58: 56.12927
2024-11-19 02:14:41 : 1/1 | 6/58: 48.90305
2024-11-19 02:14:42 : 1/1 | 7/58: 43.85905
2024-11-19 02:14:44 : 1/1 | 8/58: 41.08278
2024-11-19 02:14:46 : 1/1 | 9/58: 31.56781
2024-11-19 02:14:47 : 1/1 | 10/58: 27.31420
2024-11-19 02:14:49 : 1/1 | 11/58: 18.22247
2024-11-19 02:14:51 : 1/1 | 12/58: 18.12663
2024-11-19 02:14:52 : 1/1 | 13/58: 14.84948
2024-11-19 02:14:54 : 1/1 | 14/58: 14.56699
2024-11-19 02:14:56 : 1/1 | 15/58: 16.91566
2024-11-19 02:14:57 : 1/1 | 16/58: 15.35866
2024-11-19 02:14:59 : 1/1 | 17/58: 15.53382
2024-11-19 02:15:01 : 1/1 | 18/58: 13.57408
2024-11-19 02:15:02 : 1/1 | 19/58: 13.95835
2024-11-19 02:15:04 : 1/1 | 20/58: 12.54803
2024-11-19 02:15:06 : 1/1 | 21/58: 9.33679
2024-11-19 02:15:08 : 1/1 | 22/58: 8.70856
2024-11-19 02:15:09 : 1/1 | 23/58: 9.58533
2024-11-19 02:15:11 : 1/1 | 24/58: 11.84290
2024-11-19 02:15:13 : 1/1 | 25/58: 11.46067
2024-11-19 02:15:14 : 1/1 | 26/58: 11.01841
2024-11-19 02:15:16 : 1/1 | 27/58: 8.24411
2024-11-19 02:15:17 : 1/1 | 28/58: 8.65360
2024-11-19 02:15:19 : 1/1 | 29/58: 8.52709
2024-11-19 02:15:21 : 1/1 | 30/58: 8.10696
2024-11-19 02:15:23 : 1/1 | 31/58: 6.51938
2024-11-19 02:15:24 : 1/1 | 32/58: 6.10998
2024-11-19 02:15:26 : 1/1 | 33/58: 4.53014
2024-11-19 02:15:28 : 1/1 | 34/58: 5.58993
2024-11-19 02:15:29 : 1/1 | 35/58: 5.20420
2024-11-19 02:15:31 : 1/1 | 36/58: 5.59321
2024-11-19 02:15:33 : 1/1 | 37/58: 5.54185
2024-11-19 02:15:34 : 1/1 | 38/58: 3.47608
2024-11-19 02:15:36 : 1/1 | 39/58: 4.05513
2024-11-19 02:15:38 : 1/1 | 40/58: 2.24291
2024-11-19 02:15:39 : 1/1 | 41/58: 2.56150
2024-11-19 02:15:41 : 1/1 | 42/58: 1.30751
2024-11-19 02:15:43 : 1/1 | 43/58: 2.48825
2024-11-19 02:15:44 : 1/1 | 44/58: 1.74816
2024-11-19 02:15:46 : 1/1 | 45/58: 2.47233
2024-11-19 02:15:48 : 1/1 | 46/58: 1.86368
2024-11-19 02:15:49 : 1/1 | 47/58: 0.81900
2024-11-19 02:15:51 : 1/1 | 48/58: 1.96999
2024-11-19 02:15:53 : 1/1 | 49/58: 1.22497
2024-11-19 02:15:54 : 1/1 | 50/58: 0.71520
2024-11-19 02:15:56 : 1/1 | 51/58: 2.42195
2024-11-19 02:15:58 : 1/1 | 52/58: 1.64515
2024-11-19 02:15:59 : 1/1 | 53/58: 1.97707
2024-11-19 02:16:01 : 1/1 | 54/58: 1.97601
2024-11-19 02:16:03 : 1/1 | 55/58: 1.41296
2024-11-19 02:16:04 : 1/1 | 56/58: 0.83731
2024-11-19 02:16:06 : 1/1 | 57/58: 1.11879
2024-11-19 02:16:08 : 1/1 | 58/58: 0.66496
